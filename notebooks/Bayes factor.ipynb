{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party\n",
    "from astropy.table import Table\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.constants import G\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('../notebook/notebook.mplstyle')\n",
    "%matplotlib inline\n",
    "import corner\n",
    "import emcee\n",
    "from scipy.integrate import quad\n",
    "from scipy.misc import logsumexp\n",
    "\n",
    "# Custom\n",
    "import gala.coordinates as gc\n",
    "import gala.dynamics as gd\n",
    "import gala.integrate as gi\n",
    "import gala.potential as gp\n",
    "from gala.units import galactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From John Brewer:\n",
    "rv = -21.2 # km/s\n",
    "rv_err = 0.1 # km/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tgas = Table.read('../data/tgas.csv')\n",
    "tgas['hd_id'] = ['240430', '240429']\n",
    "\n",
    "coords = coord.SkyCoord(ra=tgas['ra']*u.deg, dec=tgas['dec']*u.deg, \n",
    "                        distance=1000./tgas['parallax']*u.pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_hat(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec'], units=None):\n",
    "    y = np.zeros(len(names))\n",
    "        \n",
    "    default_units = dict()\n",
    "    default_units['ra'] = u.degree\n",
    "    default_units['dec'] = u.degree\n",
    "    default_units['parallax'] = u.mas\n",
    "    default_units['pmra'] = u.mas/u.yr\n",
    "    default_units['pmdec'] = u.mas/u.yr\n",
    "    \n",
    "    if units is None:\n",
    "        units = [default_units[name] for name in names]\n",
    "    \n",
    "    for i,name in enumerate(names):\n",
    "        y[i] = (row[name]*default_units[name]).to(units[i]).value\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cov(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec'], units=None):\n",
    "    \n",
    "    default_err_units = dict()\n",
    "    default_err_units['ra'] = u.mas\n",
    "    default_err_units['dec'] = u.mas\n",
    "    default_err_units['parallax'] = u.mas\n",
    "    default_err_units['pmra'] = u.mas/u.yr\n",
    "    default_err_units['pmdec'] = u.mas/u.yr\n",
    "    \n",
    "    if units is None:\n",
    "        units = [default_err_units[name] for name in names]\n",
    "    \n",
    "    C = np.zeros((len(names), len(names)))\n",
    "\n",
    "    # pre-load the diagonal\n",
    "    for i,name in enumerate(names):\n",
    "        full_name = \"{}_error\".format(name)\n",
    "        C[i,i] = (row[full_name]*default_err_units[name]).to(units[i]).value**2\n",
    "\n",
    "    for i,name1 in enumerate(names):\n",
    "        for j,name2 in enumerate(names):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            full_name = \"{}_{}_corr\".format(name1, name2)\n",
    "            u_old = default_err_units[name1]*default_err_units[name2]\n",
    "            u_new = units[i]*units[j]\n",
    "            C[i,j] = (row[full_name] * np.sqrt(C[i,i]*C[j,j]) * u_old).to(u_new).value\n",
    "            C[j,i] = (row[full_name] * np.sqrt(C[i,i]*C[j,j]) * u_old).to(u_new).value\n",
    "            \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProbModel(object):\n",
    "        \n",
    "    def ln_posterior(self, pars):\n",
    "        \"\"\" \n",
    "        Up to a normalization constant, the log of the posterior pdf is just \n",
    "        the sum of the log likelihood plus the log prior.\n",
    "        \"\"\"\n",
    "        lnp = self.ln_prior(pars)\n",
    "        if np.isinf(lnp): # short-circuit if the prior is infinite (don't bother computing likelihood)\n",
    "            return lnp\n",
    "\n",
    "        lnL = self.ln_likelihood(pars).sum()\n",
    "        lnprob = lnp + lnL\n",
    "\n",
    "        if np.isnan(lnprob):\n",
    "            return -np.inf\n",
    "\n",
    "        return lnprob\n",
    "    \n",
    "    def __call__(self, pars):\n",
    "        return self.ln_posterior(pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 1\n",
    "\n",
    "The stars are a wide binary, drawn from a piecewise distribution:\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "p(a) &=& \\begin{cases}\n",
    "            a^{-1} & 100<a<3000~{\\rm au}\\\\    \n",
    "            a^{-1.6} & a \\geq 3000~{\\rm au}\\\\    \n",
    "         \\end{cases} \n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_a(a, a_min=1E-3, a_max=1E2, a_b=1.45E-2):\n",
    "    if a < a_min or a > a_max:\n",
    "        return 0.\n",
    "    \n",
    "    B = a_b**0.6\n",
    "    Cinv = np.log(a_b) - np.log(a_min) + 5*B/3 * (a_b**-0.6 - a_max**-0.6)\n",
    "    C = 1/Cinv\n",
    "    \n",
    "    if a < a_b:\n",
    "        return C / a\n",
    "        \n",
    "    else:\n",
    "        return C * B * a**-1.6\n",
    "    \n",
    "def ln_p_a(a, a_min=1E-3, a_max=1E2, a_b=1.45E-2):\n",
    "    if a < a_min or a > a_max:\n",
    "        return -np.inf\n",
    "    \n",
    "    B = a_b**0.6\n",
    "    Cinv = np.log(a_b) - np.log(a_min) + 5*B/3 * (a_b**-0.6 - a_max**-0.6)\n",
    "    C = 1/Cinv\n",
    "    \n",
    "    if a < a_b:\n",
    "        return np.log(C) - np.log(a)\n",
    "        \n",
    "    else:\n",
    "        return np.log(C) + np.log(B) - 1.6*np.log(a)\n",
    "    \n",
    "a = np.logspace(-4, 2.5, 1024)\n",
    "plt.plot(a, a*np.array([p_a(aa, a_b=1.) for aa in a]))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "res,_ = quad(p_a, 1E-3, 1E2)\n",
    "assert np.allclose(res, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypothesis1(ProbModel):\n",
    "    \n",
    "    def __init__(self, y_hat1, Cov1, y_hat2, Cov2, coord1, coord2):\n",
    "        \"\"\" \n",
    "        y_hat's should be: [parallax, pmra, pmdec, vr]\n",
    "        units should be: [mas, mas/yr, mas/yr, km/s]\n",
    "        \"\"\"\n",
    "        \n",
    "        self.y_hat1 = np.array(y_hat1)\n",
    "        self.Cov1 = Cov1\n",
    "        self.Cinv1 = np.linalg.inv(Cov1)\n",
    "        _,self.det_Cinv1 = np.linalg.slogdet(self.Cinv1/(2*np.pi))\n",
    "        \n",
    "        self.y_hat2 = np.array(y_hat2)\n",
    "        self.Cov2 = Cov2\n",
    "        self.Cinv2 = np.linalg.inv(Cov2)\n",
    "        _,self.det_Cinv2 = np.linalg.slogdet(self.Cinv2/(2*np.pi))\n",
    "        \n",
    "        # sky coordinates\n",
    "        self._sep = coord2.separation(coord1).radian\n",
    "        self._cos_sep = np.cos(self._sep)\n",
    "        \n",
    "        self._uvec1 = np.array([np.cos(coord1.ra)*np.cos(coord1.dec),\n",
    "                                np.sin(coord1.ra)*np.cos(coord1.dec),\n",
    "                                np.sin(coord1.dec)])\n",
    "        self._uvec2 = np.array([np.cos(coord2.ra)*np.cos(coord2.dec),\n",
    "                                np.sin(coord2.ra)*np.cos(coord2.dec),\n",
    "                                np.sin(coord2.dec)])\n",
    "        \n",
    "        # some assumed parameters\n",
    "        self._G = G.to(u.pc/u.Msun*u.km**2/u.s**2).value\n",
    "        self.mass = 2. # Msun\n",
    "        self.sigma_v = 25. # km/s\n",
    "    \n",
    "    def unpack_pars(self, pars):\n",
    "        \"\"\"\n",
    "        TODO: might need to rotate (vra,vdec,vr) to be (vx,vy,vz)...\n",
    "        pars are: [r1, vra1, vdec1, vr1, ln_a]\n",
    "        units are: [pc, km/s, km/s, km/s, ln(pc)]\n",
    "        \n",
    "        output y's are: [parallax1, pmra1, pmdec1, vr1] \n",
    "        output y units are: [mas, mas/yr, mas/yr, km/s] \n",
    "        \n",
    "        (4.74047E-3 km/s/pc) per (mas/yr)\n",
    "        (210.94953 mas/yr) per (km/s/pc)\n",
    "        \"\"\"\n",
    "        r1, vra1, vdec1, vr1, ln_a = pars\n",
    "        a = np.exp(ln_a)\n",
    "        \n",
    "        y1 = np.array([1000./r1, 210.94953*vra1/r1, 210.94953*vdec1/r1, vr1])\n",
    "        \n",
    "        # do some trig:\n",
    "        r2 = r1 * np.array([self._cos_sep + np.sqrt(self._cos_sep + (a/r1)**2 - 1.),\n",
    "                            self._cos_sep - np.sqrt(self._cos_sep + (a/r1)**2 - 1.)]) # two roots\n",
    "        \n",
    "        dv_mag = np.sqrt(self._G * self.mass / a) # km/s\n",
    "        \n",
    "        x1 = r1 * self._uvec1\n",
    "        x2 = r2[:,None] * self._uvec2[None]\n",
    "        dx = x2 - x1\n",
    "        dv = np.cross(dx, x2)\n",
    "        dv = dv_mag * dv / np.linalg.norm(dv, axis=-1)[:,None]\n",
    "        \n",
    "        v1 = np.array([vra1, vdec1, vr1])\n",
    "        v2 = np.zeros((2,2,3))\n",
    "        v2[:,0] = v1 + dv\n",
    "        v2[:,1] = v1 - dv\n",
    "        \n",
    "        y2 = np.zeros((2,2,4))\n",
    "        y2[0,:,0] = 1000./r2[0]\n",
    "        y2[1,:,0] = 1000./r2[1]\n",
    "        y2[:,:,1:3] = 210.94953 * v2[...,:2] / r2[:,None]\n",
    "        y2[:,:,3] = v2[...,2]\n",
    "\n",
    "        return y1, y2.reshape(-1, 4)\n",
    "        \n",
    "    def ln_likelihood(self, pars):\n",
    "        y1,y2 = self.unpack_pars(pars)\n",
    "        \n",
    "        if np.any(np.isnan(y1)) or np.any(np.isnan(y2)):\n",
    "            return -np.inf\n",
    "        \n",
    "        dy1 = (y1 - self.y_hat1)\n",
    "        dy2 = (y2 - self.y_hat2)\n",
    "        \n",
    "        ln_p1 = 0.5 * self.det_Cinv1 - 0.5 * (dy1.T @ self.Cinv1 @ dy1)\n",
    "        ln_p2 = 0.5 * self.det_Cinv2 - 0.5 * np.array([dy2[i].T @ self.Cinv2 @ dy2[i] for i in range(4)])\n",
    "        return ln_p1 + logsumexp(ln_p2)\n",
    "\n",
    "    def ln_prior(self, pars):\n",
    "        r1, vra1, vdec1, vr1, ln_a = pars\n",
    "        # pc, km/s, km/s, km/s, pc\n",
    "        \n",
    "        lp = 0.\n",
    "        \n",
    "        v = np.array([vra1, vdec1, vr1])\n",
    "        lp += -0.5 * np.sum(v**2 / self.sigma_v**2) - 0.5*np.log(2*np.pi*self.sigma_v**2)\n",
    "        \n",
    "#         lp += ln_p_a(np.exp(ln_a))\n",
    "        \n",
    "        # Assume uniform in lna out to wide separation:\n",
    "        ln_amin = np.log(1E-3) # pc\n",
    "        ln_amax = np.log(1E2) # pc\n",
    "        if ln_a < ln_amin or ln_a > ln_amax:\n",
    "            return -np.inf\n",
    "        \n",
    "        C = 1/(ln_amax-ln_amin)\n",
    "        lp += np.log(C)\n",
    "        \n",
    "        r_lim = 300. # pc\n",
    "        if r1 > r_lim:\n",
    "            return -np.inf\n",
    "        lp += np.log(3/r_lim**3) + 2*np.log(r1)\n",
    "        \n",
    "        return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat1 = get_y_hat(tgas[0], ['parallax', 'pmra', 'pmdec'])\n",
    "yhat2 = get_y_hat(tgas[1], ['parallax', 'pmra', 'pmdec'])\n",
    "yhat1 = np.concatenate((yhat1, [rv]))\n",
    "yhat2 = np.concatenate((yhat2, [rv]))\n",
    "\n",
    "Cov1 = np.zeros((4,4))\n",
    "Cov1[:3,:3] = get_cov(tgas[0], ['parallax', 'pmra', 'pmdec'])\n",
    "Cov1[3,3] = rv_err**2\n",
    "\n",
    "Cov2 = np.zeros((4,4))\n",
    "Cov2[:3,:3] = get_cov(tgas[1], ['parallax', 'pmra', 'pmdec'])\n",
    "Cov2[3,3] = rv_err**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1 = Hypothesis1(yhat1, Cov1, yhat2, Cov2, coords[0], coords[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.array([1000./yhat1[0], 4.74047*yhat1[1]/yhat1[0], 4.74047*yhat1[2]/yhat1[0], rv, np.log(0.6)])\n",
    "H1.ln_likelihood(p0), H1.ln_prior(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 64\n",
    "ntemps = 16\n",
    "ndim = len(p0)\n",
    "sampler = emcee.PTSampler(ntemps, nwalkers, ndim, H1.ln_likelihood, H1.ln_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_p0 = np.random.normal(p0, 1E-3*np.abs(p0), size=(ntemps, nwalkers, ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sampler.reset()\n",
    "pos,_,_ = sampler.run_mcmc(all_p0, N=128)\n",
    "sampler.reset()\n",
    "pos,_,_ = sampler.run_mcmc(pos, N=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler.acor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('magma')\n",
    "norm = Normalize(0, ntemps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(ndim):\n",
    "    plt.figure()\n",
    "    for i in range(ntemps)[::-1]:\n",
    "        color = cmap(norm(i))\n",
    "        j = 0\n",
    "        plt.plot(sampler.chain[i,j,:,k], marker='', alpha=0.2, \n",
    "                 drawstyle='steps-mid', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(ndim):\n",
    "#     plt.figure()\n",
    "    \n",
    "#     i = 0 # zero temperature?    \n",
    "#     for j in range(nwalkers):\n",
    "#         plt.plot(sampler.chain[i,j,:,k], marker='', alpha=0.2, \n",
    "#                  drawstyle='steps-mid', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.thermodynamic_integration_log_evidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = corner.corner(sampler.flatchain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2\n",
    "\n",
    "The stars are independent draws from uniform space density prior and Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hypothesis2(ProbModel):\n",
    "    \n",
    "    def __init__(self, y_hat, Cov, skycoord):\n",
    "        \"\"\" \n",
    "        y_hat should be: [parallax, pmra, pmdec, vr]\n",
    "        units should be: [mas, mas/yr, mas/yr, km/s]\n",
    "        \"\"\"\n",
    "        \n",
    "        self.y_hat = np.array(y_hat)\n",
    "        self.Cov = Cov\n",
    "        self.Cinv = np.linalg.inv(Cov)\n",
    "        _,self.det_Cinv = np.linalg.slogdet(self.Cinv/(2*np.pi))\n",
    "        \n",
    "        self.sigma_v = 25. # km/s\n",
    "    \n",
    "    def unpack_pars(self, pars):\n",
    "        \"\"\"\n",
    "        pars are: [r, vra, vdec, vr]\n",
    "        units are: [pc, km/s, km/s, km/s]\n",
    "        \n",
    "        output y: [parallax, pmra, pmdec, vr] \n",
    "        output y units: [mas, mas/yr, mas/yr, km/s] \n",
    "        \n",
    "        (4.74047E-3 km/s/pc) per (mas/yr)\n",
    "        (210.94953 mas/yr) per (km/s/pc)\n",
    "        \"\"\"\n",
    "        r, vra, vdec, vr = pars\n",
    "        y = np.array([1000./r, 210.94953*vra/r, 210.94953*vdec/r, vr])\n",
    "        return y\n",
    "        \n",
    "    def ln_likelihood(self, pars):\n",
    "        y = self.unpack_pars(pars)\n",
    "        \n",
    "        if np.any(np.isnan(y)):\n",
    "            return -np.inf\n",
    "        \n",
    "        dy = (y - self.y_hat)        \n",
    "        ln_p = 0.5 * self.det_Cinv - 0.5 * (dy.T @ self.Cinv @ dy)\n",
    "        return ln_p\n",
    "\n",
    "    def ln_prior(self, pars):\n",
    "        r, vra, vdec, vr = pars\n",
    "        \n",
    "        lp = 0.\n",
    "        \n",
    "        v = np.array([vra, vdec, vr])\n",
    "        lp += -0.5 * np.sum(v**2 / self.sigma_v**2) - 0.5*np.log(2*np.pi*self.sigma_v**2)\n",
    "        \n",
    "        r_lim = 300. # pc\n",
    "        if r > r_lim:\n",
    "            return -np.inf\n",
    "        lp += np.log(3/r_lim**3) + 2*np.log(r)\n",
    "        \n",
    "        return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2_1 = Hypothesis2(yhat1, Cov1, coords[0])\n",
    "p0 = np.array([1000./yhat1[0], 4.74047*yhat1[1]/yhat1[0], 4.74047*yhat1[2]/yhat1[0], rv])\n",
    "H2_1.ln_likelihood(p0), H2_1.ln_prior(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 64\n",
    "ntemps = 16\n",
    "ndim = len(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = []\n",
    "for yhat,Cov,coo in zip([yhat1,yhat2], [Cov1,Cov2], coords):\n",
    "    H2 = Hypothesis2(yhat, Cov, coo)\n",
    "    \n",
    "    p0 = np.array([1000./yhat[0], 4.74047*yhat[1]/yhat[0], 4.74047*yhat[2]/yhat[0], rv])\n",
    "    all_p0 = np.random.normal(p0, 1E-3*np.abs(p0), size=(ntemps, nwalkers, ndim))\n",
    "    \n",
    "    sampler = emcee.PTSampler(ntemps, nwalkers, ndim, H2.ln_likelihood, H2.ln_prior)\n",
    "\n",
    "    sampler.reset()\n",
    "    pos,_,_ = sampler.run_mcmc(all_p0, N=128)\n",
    "    sampler.reset()\n",
    "    pos,_,_ = sampler.run_mcmc(pos, N=1024)\n",
    "    \n",
    "    samplers.append(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers[0].thermodynamic_integration_log_evidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers[1].thermodynamic_integration_log_evidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vegas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integ = vegas.Integrator([(102, 109), \n",
    "                          (40, 50), (-20, -10), (-22.2, -20.2), \n",
    "                          (0,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vegas_derp(p0):\n",
    "    return np.exp(H1.ln_likelihood(p0) + H1.ln_prior(p0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = integ(vegas_derp, nitn=10, neval=100000)\n",
    "print(result.summary())\n",
    "print('result = %s    Q = %.2f' % (result, result.Q))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gala-dev]",
   "language": "python",
   "name": "conda-env-gala-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}